{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPARK SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Dataframes from Python Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pandas_df = pd.read_csv(\"/resources/data/iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sepal_length  sepal_width  petal_length  petal_width species\n",
       "23           5.1          3.3           1.7          0.5  setosa"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.context.HiveContext at 0x7f33a13147b8>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqlContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark_df = sqlContext.createDataFrame(pandas_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|species|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "|         5.1|        3.5|         1.4|        0.2| setosa|\n",
      "|         4.9|        3.0|         1.4|        0.2| setosa|\n",
      "|         4.7|        3.2|         1.3|        0.2| setosa|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame from CSV files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Using Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-------+\n",
      "|petal_length|petal_width|sepal_length|sepal_width|species|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "|         1.4|        0.2|         5.1|        3.5| setosa|\n",
      "|         1.4|        0.2|         4.9|        3.0| setosa|\n",
      "|         1.3|        0.2|         4.7|        3.2| setosa|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load a text file and convert each line to a tuple.\n",
    "from pyspark.sql import Row\n",
    "    \n",
    "data = sc.textFile('/resources/data/iris.csv')\n",
    "header = data.first() #extract header\n",
    "fields = (data.filter(lambda line: line != header) \\\n",
    "              .map(lambda line: line.split(',')) \\\n",
    "              .map(lambda line : Row(sepal_length=float(line[0]), sepal_width=float(line[1])\n",
    "                                     , petal_length = float(line[2]), petal_width = float(line[3])\n",
    "                                     , species = line[4])\n",
    "                   )\n",
    "          )                          \n",
    "# Create DataFrame from RDD. using createDataFrame() or toDF()\n",
    "df0 = sqlContext.createDataFrame(fields)\n",
    "df0.show(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 2. Using Schema  - StructType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+-------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|species|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "|         5.1|        3.5|         1.4|        0.2| setosa|\n",
      "|         4.9|        3.0|         1.4|        0.2| setosa|\n",
      "|         4.7|        3.2|         1.3|        0.2| setosa|\n",
      "+------------+-----------+------------+-----------+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load a text file and convert each line to a tuple.\n",
    "from pyspark.sql.types import *\n",
    "    \n",
    "data = sc.textFile('/resources/data/iris.csv')\n",
    "header = data.first() #extract header\n",
    "fields = (\n",
    "          data.filter(lambda line: line != header) \\\n",
    "              .map(lambda line: line.split(',')) \\\n",
    "              .map(lambda line : [float(line[0]), float(line[1]) \\\n",
    "                                , float(line[2]), float(line[3])\\\n",
    "                                , line[4]]\n",
    "                  )\n",
    "          )\n",
    "\n",
    "schema = StructType(\n",
    "                [StructField('sepal_length', FloatType(), True),\n",
    "                 StructField('sepal_width', FloatType(), True),\n",
    "                 StructField('petal_length', FloatType(), True),\n",
    "                 StructField('petal_width', FloatType(), True),\n",
    "                 StructField('species', StringType(), True)])\n",
    "\n",
    "df0 = sqlContext.createDataFrame(fields,schema)\n",
    "df0.show(n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Using *spark.csv* library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = (sqlContext.read\n",
    "                .format('com.databricks.spark.csv')\n",
    "                .options(header='true', inferschema='true')\n",
    "                .load('/resources/data/car_crashes.csv')\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the datframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- total: double (nullable = true)\n",
      " |-- speeding: double (nullable = true)\n",
      " |-- alcohol: double (nullable = true)\n",
      " |-- not_distracted: double (nullable = true)\n",
      " |-- no_previous: double (nullable = true)\n",
      " |-- ins_premium: double (nullable = true)\n",
      " |-- ins_losses: double (nullable = true)\n",
      " |-- abbrev: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+------------------+------------------+------------------+-----------+----------+------+\n",
      "|total|          speeding|           alcohol|    not_distracted|       no_previous|ins_premium|ins_losses|abbrev|\n",
      "+-----+------------------+------------------+------------------+------------------+-----------+----------+------+\n",
      "| 18.8| 7.332000000000001|              5.64|18.048000000000002|             15.04|     784.55|    145.08|    AL|\n",
      "| 18.1|             7.421|             4.525|16.290000000000003|            17.014|    1053.48|    133.93|    AK|\n",
      "| 18.6|              6.51| 5.208000000000001|            15.624|            17.856|     899.47|    110.35|    AZ|\n",
      "| 22.4|             4.032|             5.824|21.055999999999997|             21.28|     827.34|    142.39|    AR|\n",
      "| 12.0|               4.2|              3.36|             10.92|             10.68|     878.41|    165.63|    CA|\n",
      "| 13.6|             5.032|3.8080000000000003|10.743999999999998|             12.92|      835.5|    139.91|    CO|\n",
      "| 10.8|             4.968|             3.888|             9.396|             8.856|    1068.73|    167.02|    CT|\n",
      "| 16.2| 6.156000000000001|              4.86|            14.094|            16.038|    1137.87|    151.48|    DE|\n",
      "|  5.9|2.0060000000000002|1.5930000000000002|               5.9|               5.9|    1273.89|    136.05|    DC|\n",
      "| 17.9|             3.759| 5.190999999999999|            16.468|            16.826|    1160.13|    144.18|    FL|\n",
      "| 15.6|             2.964|               3.9|             14.82|            14.508|     913.15|     142.8|    GA|\n",
      "| 17.5|              9.45|             7.175|             14.35|            15.225|     861.18|    120.92|    HI|\n",
      "| 15.3| 5.508000000000001|             4.437|            13.005|14.994000000000002|     641.96|     82.75|    ID|\n",
      "| 12.8|4.6080000000000005|             4.352|            12.032|12.288000000000002|     803.11|    139.15|    IL|\n",
      "| 14.5|             3.625|             4.205|            13.775|            13.775|     710.46|    108.92|    IN|\n",
      "| 15.7|2.6689999999999996|             3.925|            15.229|13.658999999999999|     649.06|    114.47|    IA|\n",
      "| 17.8|             4.806|             4.272|13.706000000000001|             15.13|     780.45|     133.8|    KS|\n",
      "| 21.4|             4.066|             4.922|16.691999999999997|            16.264|     872.51|    137.13|    KY|\n",
      "| 20.5|             7.175|             6.765|            14.965|             20.09|    1281.55|    194.78|    LA|\n",
      "| 15.1|5.7379999999999995|              4.53|            13.137|            12.684|     661.88|     96.57|    ME|\n",
      "+-----+------------------+------------------+------------------+------------------+-----------+----------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|           alcohol|\n",
      "+------------------+\n",
      "|              5.64|\n",
      "|             4.525|\n",
      "| 5.208000000000001|\n",
      "|             5.824|\n",
      "|              3.36|\n",
      "|3.8080000000000003|\n",
      "|             3.888|\n",
      "|              4.86|\n",
      "|1.5930000000000002|\n",
      "| 5.190999999999999|\n",
      "|               3.9|\n",
      "|             7.175|\n",
      "|             4.437|\n",
      "|             4.352|\n",
      "|             4.205|\n",
      "|             3.925|\n",
      "|             4.272|\n",
      "|             4.922|\n",
      "|             6.765|\n",
      "|              4.53|\n",
      "+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('alcohol').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To run SQL queries, we need to register the dataframe as a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.registerTempTable('car_crashes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
